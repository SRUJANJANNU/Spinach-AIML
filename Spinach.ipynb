{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRUJANJANNU/Spinach-AIML/blob/main/Spinach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade9d9e3",
      "metadata": {
        "id": "ade9d9e3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvklMuLAgIVd",
        "outputId": "c26ba35c-dfdd-423d-e3e1-055540c0b451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "id": "pvklMuLAgIVd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98b743e6",
      "metadata": {
        "id": "98b743e6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn; sn.set(font_scale=1.4)\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7481895d",
      "metadata": {
        "id": "7481895d"
      },
      "outputs": [],
      "source": [
        "class_names = ['ANTHRACNOSE', 'DOWNEYMILDEW', 'GOODLEAF', 'LEAFMINER', 'SLUGINFECTED']\n",
        "class_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n",
        "\n",
        "nb_classes = len(class_names)\n",
        "\n",
        "IMAGE_SIZE = (150, 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17f53cbe",
      "metadata": {
        "id": "17f53cbe"
      },
      "outputs": [],
      "source": [
        "#datasets = ['/content/drive/MyDrive/AIML_SPINACH_DATASET/TRAIN', '/content/drive/MyDrive/AIML_SPINACH_DATASET/VALID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f345a15",
      "metadata": {
        "id": "2f345a15"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "        Load the data:\n",
        "            - 14,034 images to train the network.\n",
        "            - 3,000 images to evaluate how accurately the network learned to classify images.\n",
        "    \"\"\"\n",
        "\n",
        "    datasets = ['/content/drive/MyDrive/AIML_SPINACH_DATASET/TRAIN', '/content/drive/MyDrive/AIML_SPINACH_DATASET/VALID']\n",
        "    output = []\n",
        "\n",
        "    # Iterate through training and test sets\n",
        "    for dataset in datasets:\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        print(\"Loading {}\".format(dataset))\n",
        "\n",
        "        # Iterate through each folder corresponding to a category\n",
        "        for folder in os.listdir(dataset):\n",
        "            label = class_names_label[folder]\n",
        "\n",
        "            # Iterate through each image in our folder\n",
        "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
        "\n",
        "                # Get the path name of the image\n",
        "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "\n",
        "                # Open and resize the img\n",
        "                image = cv2.imread(img_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "                # Append the image and its corresponding label to the output\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "        images = np.array(images, dtype = 'float32')\n",
        "        labels = np.array(labels, dtype = 'int32')\n",
        "\n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55e5e37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "c55e5e37",
        "outputId": "d914a00a-726f-429a-8fbd-349069f9ca02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading /content/drive/MyDrive/AIML_SPINACH_DATASET/TRAIN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 31/31 [00:34<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-bdc5f874dbf6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-51f535c5279b>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Iterate through each folder corresponding to a category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_names_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Iterate through each image in our folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'GOOD LEAF'"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72ab8960",
      "metadata": {
        "id": "72ab8960"
      },
      "outputs": [],
      "source": [
        "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62153ab8",
      "metadata": {
        "id": "62153ab8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "_, train_counts = np.unique(train_labels, return_counts=True)\n",
        "_, test_counts = np.unique(test_labels, return_counts=True)\n",
        "pd.DataFrame({'train': train_counts,\n",
        "                    'test': test_counts},\n",
        "             index=class_names\n",
        "            ).plot.bar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f96c3a4",
      "metadata": {
        "id": "1f96c3a4"
      },
      "outputs": [],
      "source": [
        "plt.pie(train_counts,\n",
        "        explode=(0, 0, 0, 0, 0) ,\n",
        "        labels=class_names,\n",
        "        autopct='%1.1f%%')\n",
        "plt.axis('equal')\n",
        "plt.title('Proportion of each observed category')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f34bc7",
      "metadata": {
        "id": "a0f34bc7"
      },
      "outputs": [],
      "source": [
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b798aea9",
      "metadata": {
        "id": "b798aea9"
      },
      "outputs": [],
      "source": [
        "def display_random_image(class_names, images, labels):\n",
        "    \"\"\"\n",
        "        Display a random image from the images array and its correspond label from the labels array.\n",
        "    \"\"\"\n",
        "\n",
        "    index = np.random.randint(images.shape[0])\n",
        "    plt.figure()\n",
        "    plt.imshow(images[index])\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a83de53",
      "metadata": {
        "id": "0a83de53"
      },
      "outputs": [],
      "source": [
        "display_random_image(class_names, train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4212e727",
      "metadata": {
        "id": "4212e727"
      },
      "outputs": [],
      "source": [
        "def display_examples(class_names, images, labels):\n",
        "    \"\"\"\n",
        "        Display 25 images from the images array with its corresponding labels\n",
        "    \"\"\"\n",
        "\n",
        "    fig = plt.figure(figsize=(12,10))\n",
        "    fig.suptitle(\"Some examples of images of the dataset\", fontsize=20)\n",
        "    for i in range(10):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "        plt.xlabel(class_names[labels[i]])\n",
        "    plt.show()\n",
        "display_examples(class_names, train_images, train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b569dbe7",
      "metadata": {
        "id": "b569dbe7"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d090dd76",
      "metadata": {
        "id": "d090dd76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d06b7f5",
      "metadata": {
        "id": "3d06b7f5"
      },
      "outputs": [],
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(5))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39227b0",
      "metadata": {
        "id": "e39227b0"
      },
      "outputs": [],
      "source": [
        "test_images.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08b46caa",
      "metadata": {
        "id": "08b46caa"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e1510a",
      "metadata": {
        "id": "14e1510a"
      },
      "outputs": [],
      "source": [
        "# An epoch means training the neural network with all the\n",
        "# training data for one cycle. Here I use 10 epochs\n",
        "history = model.fit(train_images, train_labels, epochs=15,\n",
        "                    validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d1b9bf",
      "metadata": {
        "id": "b6d1b9bf"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'],label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'],label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,\n",
        "                                     test_labels,\n",
        "                                     verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde67bf4",
      "metadata": {
        "id": "bde67bf4"
      },
      "outputs": [],
      "source": [
        "print('Test Accuracy is',test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2e842da",
      "metadata": {
        "id": "e2e842da"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot loss values vs epoch\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b8ed64",
      "metadata": {
        "id": "79b8ed64"
      },
      "outputs": [],
      "source": [
        "'''from keras.preprocessing.image import ImageDataGenerator\n",
        "General_datagen = ImageDataGenerator(rescale=1./255, )\n",
        "test_data = General_datagen.flow_from_directory('SPINACH/TEST/', target_size=(150,150),)\n",
        "print(test_data)\n",
        "print('data groups:', len(test_data))\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a970e71a",
      "metadata": {
        "id": "a970e71a"
      },
      "outputs": [],
      "source": [
        "def tst_data():\n",
        "    \"\"\"\n",
        "        Load the data:\n",
        "            - 14,034 images to train the network.\n",
        "            - 3,000 images to evaluate how accurately the network learned to classify images.\n",
        "    \"\"\"\n",
        "\n",
        "    datasets = ['SPINACH/VALID','SPINACH/TEST']\n",
        "    output = []\n",
        "\n",
        "    # Iterate through training and test sets\n",
        "    for dataset in datasets:\n",
        "\n",
        "        images = []\n",
        "        labels = []\n",
        "\n",
        "        print(\"Loading {}\".format(dataset))\n",
        "\n",
        "        # Iterate through each folder corresponding to a category\n",
        "        for folder in os.listdir(dataset):\n",
        "            label = class_names_label[folder]\n",
        "\n",
        "            # Iterate through each image in our folder\n",
        "            for file in tqdm(os.listdir(os.path.join(dataset, folder))):\n",
        "\n",
        "                # Get the path name of the image\n",
        "                img_path = os.path.join(os.path.join(dataset, folder), file)\n",
        "\n",
        "                # Open and resize the img\n",
        "                image = cv2.imread(img_path)\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "                image = cv2.resize(image, IMAGE_SIZE)\n",
        "\n",
        "                # Append the image and its corresponding label to the output\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "        images = np.array(images, dtype = 'float32')\n",
        "        labels = np.array(labels, dtype = 'int32')\n",
        "\n",
        "        output.append((images, labels))\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae5f48f",
      "metadata": {
        "id": "eae5f48f"
      },
      "outputs": [],
      "source": [
        "(dummy_DATA, dummydata_LBS),(test_data, testdata_labels) = tst_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "494c0773",
      "metadata": {
        "id": "494c0773"
      },
      "outputs": [],
      "source": [
        "test_data=test_data/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82aff2e8",
      "metadata": {
        "id": "82aff2e8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "prediction = model.predict(test_data)\n",
        "pred_label = np.argmax(prediction, axis = 1)\n",
        "pred_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22357bdc",
      "metadata": {
        "id": "22357bdc"
      },
      "outputs": [],
      "source": [
        "CM = confusion_matrix(testdata_labels, pred_label)\n",
        "ax = plt.axes()\n",
        "sn.heatmap(CM, annot=True,\n",
        "           annot_kws={\"size\": 15},\n",
        "           xticklabels=class_names,\n",
        "           yticklabels=class_names, ax = ax)\n",
        "ax.set_title('Confusion matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eacb991",
      "metadata": {
        "id": "1eacb991"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions = model.predict(test_data)     # Vector of probabilities\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2bc2cb",
      "metadata": {
        "id": "9d2bc2cb"
      },
      "outputs": [],
      "source": [
        "pred_labels = np.argmax(predictions, axis = 1)\n",
        "pred_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4ba927e",
      "metadata": {
        "id": "a4ba927e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "accuracy_score(pred_labels,testdata_labels)\n",
        "print(classification_report(pred_labels,testdata_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad24042",
      "metadata": {
        "id": "3ad24042"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_data)     # Vector of probabilities\n",
        "pred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n",
        "\n",
        "for i in range(3):\n",
        "    display_random_image(class_names, test_data, pred_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6236c5",
      "metadata": {
        "id": "0b6236c5"
      },
      "outputs": [],
      "source": [
        "#### https://www.analyticsvidhya.com/blog/2022/01/image-classification-using-machine-learning/\n",
        "### https://www.kaggle.com/code/vincee/intel-image-classification-cnn-keras\n",
        "### https://www.kaggle.com/code/vincee/intel-image-classification-cnn-keras"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}